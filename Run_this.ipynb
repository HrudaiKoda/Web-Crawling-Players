{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of Edt_1_Final_push.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Gokul_IndicWiki",
      "language": "python",
      "name": "gokul_indicwiki"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUl-pR0TZaN-"
      },
      "source": [
        "#Run any one cell to select a certain url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcKCEpUGuwZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf862f4-13a1-4700-dc34-9bdc3bd2a59b"
      },
      "source": [
        "!sudo apt-get install chromium-chromedriver\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install chromium-chromedriver"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (90.0.4430.93-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 93 not upgraded.\n",
            "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (90.0.4430.93-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 93 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQShvi2kawzd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbfcc45b-2e51-4366-a067-569866356467"
      },
      "source": [
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "password = getpass.getpass()\n",
        "command = \"sudo -S apt-get install chromium-chromedriver\"\n",
        "os.system('echo %s | %s' % (password, command))\n",
        "command = \"sudo -S apt-get update\"\n",
        "os.system('echo %s | %s' % (password, command))\n",
        "command = \"sudo -S apt-get install chromium-chromedriver\"\n",
        "os.system('echo %s | %s' % (password, command))\n",
        "\n",
        "# If facing issues with the default firefox driver for webscraping using selenium , run the below code\n",
        "# !sudo apt-get install chromium-chromedriver\n",
        "# !sudo apt-get update\n",
        "# !sudo apt-get install chromium-chromedriver\n",
        "!pip install selenium\n",
        "# Here the chrome driver is being used , hence replace firefox with Chrome driver as given below\n",
        "!pip install webdriver-manager\n",
        "\n",
        "from selenium import webdriver\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome(ChromeDriverManager().install(), options=options)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.7/dist-packages (3.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (2.23.0)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (5.0.2)\n",
            "Requirement already satisfied: crayons in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (0.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (2020.12.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from crayons->webdriver-manager) (0.4.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_vsk5BDtuAO"
      },
      "source": [
        "#Alphabetical parse url\n",
        "#url = \"https://www.espncricinfo.com/ci/content/player/country.html?country=6;alpha=A\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4UqagRqtuAS"
      },
      "source": [
        "from bs4 import BeautifulSoup as bf\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from selenium import webdriver\n",
        "\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "# driver = webdriver.Firefox()\n",
        "# driver = webdriver.Chrome(options=options)\n",
        "driver = wd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMcBcnhbjwX4"
      },
      "source": [
        "def evaluate(html):\n",
        "  select_divs = html.find_all('div',class_=\"card overflow-hidden mb-3\")\n",
        "  exist = 0\n",
        "  location = 0\n",
        "  for i in range(len(select_divs)):\n",
        "    check = \"\"\n",
        "    try:\n",
        "      check = select_divs[i].find('p',class_=\"benton-bold pl-3 pt-4 pb-3 m-0 player-card-header\").text\n",
        "    except:\n",
        "      k = 1\n",
        "    if(check == \"Career Averages\"):\n",
        "      exist = 1\n",
        "      location = i\n",
        "      break\n",
        "  try:\n",
        "    position = select_divs[location]\n",
        "  except:\n",
        "    position = \"\"\n",
        "    exist = 0\n",
        "  return exist,position"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM0_9SZXVLVk"
      },
      "source": [
        "def get_player_image():\n",
        "    # For fixing installation errors on linux: `sudo apt install firefox-geckodriver`\n",
        "    global driver\n",
        "    images = driver.find_elements_by_tag_name('img')\n",
        "    images = [image for image in images if \"player-card__face\" in image.get_attribute(\"class\")]\n",
        "    if len(images) < 1:\n",
        "        return [\"image\"], [\"\"]\n",
        "    print(images[0].get_attribute(\"src\"))\n",
        "    return [\"image\"], [images[0].get_attribute(\"src\")]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxY2A7SCVLVk"
      },
      "source": [
        "# Get trophy info\n",
        "def get_major_trophies_information(major_trophies_soup):\n",
        "    major_trophies_results = {}\n",
        "    all_h5_tags = major_trophies_soup.find_all('h5', class_=\"border-bottom-gray-300 m-0 pl-3 pb-2 table-header\")\n",
        "    if all_h5_tags is None:\n",
        "        return None\n",
        "    try:\n",
        "        required_h5_tag = all_h5_tags[0]\n",
        "    except:\n",
        "        print('-'*50)\n",
        "        print(all_h5_tags)\n",
        "        print('-'*50)\n",
        "    for h5_tag in all_h5_tags:\n",
        "        if str(h5_tag.text).strip() == \"In Major Trophies\":\n",
        "            required_h5_tag = h5_tag\n",
        "            break\n",
        "    if str(required_h5_tag.text).strip() != \"In Major Trophies\":\n",
        "        return [\"Major trophies\"], [[major_trophies_results]]\n",
        "    major_trophies_table_head = required_h5_tag.findNext('thead')\n",
        "    major_trophies_table_headings = major_trophies_table_head.find_all('th')\n",
        "    major_trophies_table_headings_count = 0\n",
        "    major_trophies_headings_list = []\n",
        "    for table_heading in major_trophies_table_headings:\n",
        "        major_trophies_headings_list.append(table_heading.text)\n",
        "    major_trophies_table_headings_count = len(major_trophies_headings_list)\n",
        "    # print('Major Trophies table Head count', major_trophies_table_headings_count)\n",
        "    current_title = \"HOME\"\n",
        "    major_trophies_table_body = major_trophies_table_head.findNext('tbody')\n",
        "    major_trophies_table_data = major_trophies_table_body.find_all('td')\n",
        "    t = 0\n",
        "    for table_data in major_trophies_table_data:\n",
        "        attribute_number = t % major_trophies_table_headings_count\n",
        "        if(attribute_number != 0):\n",
        "            major_trophies_results[current_title][major_trophies_headings_list[attribute_number]] = table_data.text\n",
        "        else:\n",
        "            current_title = table_data.text\n",
        "            major_trophies_results[current_title] = {}\n",
        "        t += 1\n",
        "    # print(major_trophies_results)\n",
        "    return [\"Major trophies\"], [[major_trophies_results]]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLrgeH90VLVl"
      },
      "source": [
        "# Statistical analysis - Home, Away stats and function call to trophy info\n",
        "def get_statistical_analysis_and_trophy_info_and_image(req):\n",
        "    analysis_labels = []\n",
        "    analysis_results = []\n",
        "    analysis_url = req.url + \"/bowling-batting-stats\"\n",
        "    #analysis_url = \"https://www.espncricinfo.com/player/virat-kohli-253802/bowling-batting-stats\"\n",
        "    \n",
        "    # selecting dropdown option\n",
        "    global driver\n",
        "    driver.get(analysis_url)\n",
        "    # loading page\n",
        "    time.sleep(2)\n",
        "    dropdowns = driver.find_elements_by_class_name('dropdown-container')\n",
        "    for dropdown in dropdowns:\n",
        "        is_format_dropdown = str(dropdown.find_elements_by_tag_name('button')[0].text).strip() in [\"Test\", \"ODI\", \"T20I\", \"Test+ODI+T20I\"]\n",
        "        is_role_dropdown = str(dropdown.find_elements_by_tag_name('button')[0].text).strip() in [\"Batting\", \"Bowling\", \"Fielding\", \"Allround\"]\n",
        "        if (not is_format_dropdown) and (not is_role_dropdown):\n",
        "            continue\n",
        "        required_span_text = \"Test+ODI+T20I\"\n",
        "        if is_role_dropdown:\n",
        "            required_span_text = \"Allround\"\n",
        "        dropdown.find_elements_by_tag_name('button')[0].click()\n",
        "        all_list_items = dropdown.find_elements_by_tag_name('li')\n",
        "        for list_item in all_list_items:\n",
        "            span_text = list_item.find_elements_by_tag_name('span')[0].text\n",
        "            if span_text == required_span_text:\n",
        "                list_item.click()\n",
        "                break\n",
        "    # waiting for changes to load\n",
        "    time.sleep(3)\n",
        "    analysis_page = driver.page_source\n",
        "    analysis_soup = bf(analysis_page, \"html.parser\")\n",
        "    \n",
        "    all_h5_tags = analysis_soup.find_all('h5', class_=\"border-bottom-gray-300 m-0 pl-3 pb-2 table-header\")\n",
        "    # print(all_h5_tags)\n",
        "    if len(all_h5_tags) is not 0:\n",
        "      try:\n",
        "          required_h5_tag = all_h5_tags[0]\n",
        "      except:\n",
        "          print('-'*50)\n",
        "          print(all_h5_tags)\n",
        "          print('-'*50)\n",
        "      for h5_tag in all_h5_tags:\n",
        "          if str(h5_tag.text).strip() == \"Home vs Away\":\n",
        "              required_h5_tag = h5_tag\n",
        "              break\n",
        "      if str(required_h5_tag.text).strip() != \"Home vs Away\":\n",
        "          return get_major_trophies_information(analysis_soup)\n",
        "      analysis_table_head = required_h5_tag.findNext('thead')\n",
        "      analysis_table_headings = analysis_table_head.find_all('th')\n",
        "      analysis_table_headings_count = 0\n",
        "      analysis_table_headings_list = []\n",
        "      for table_heading in analysis_table_headings:\n",
        "          analysis_table_headings_list.append(table_heading.text)\n",
        "      analysis_table_headings_count = len(analysis_table_headings_list)\n",
        "      # print('Analysis table Head count', analysis_table_headings_count)\n",
        "      current_title = \"HOME\"\n",
        "      analysis_table_body = analysis_table_head.findNext('tbody')\n",
        "      analysis_table_data = analysis_table_body.find_all('td')\n",
        "      t = 0\n",
        "      for table_data in analysis_table_data:\n",
        "          attribute_number = t % analysis_table_headings_count\n",
        "          if(attribute_number != 0):\n",
        "              analysis_results.append(table_data.text)\n",
        "              analysis_labels.append(current_title + \"_\" + analysis_table_headings_list[attribute_number])\n",
        "          else:\n",
        "              current_title = table_data.text.upper()\n",
        "          t += 1\n",
        "      trophy_label, trophy_result = get_major_trophies_information(analysis_soup)\n",
        "      image_label, image_result = get_player_image()\n",
        "    else:\n",
        "      return [] , []\n",
        "    # for i in range(len(analysis_labels)):\n",
        "    #     print(f'{analysis_labels[i]} : {analysis_results[i]}')\n",
        "\n",
        "    return analysis_labels + trophy_label + image_label, analysis_results + trophy_result + image_result"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TAwtcBXVLVl"
      },
      "source": [
        "def find_relations(Relations):\n",
        "    relations_container = Relations.find_next('div')\n",
        "    individual_relations = relations_container.find_all('span')\n",
        "    total_relations = list()\n",
        "    for i in range(len(individual_relations)):\n",
        "        name = individual_relations[i].find('h5').text\n",
        "        bond = individual_relations[i].find('p').text\n",
        "        total_relations.append([name,bond])\n",
        "    return total_relations"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A_yiQzdtuAU"
      },
      "source": [
        "#Get relevant information related to a player using each player's url\n",
        "def load(req,final_list_players,ind,u,debut_url):\n",
        "    lab = list()\n",
        "    result = list()\n",
        "    soup = bf(req.text,\"html.parser\")\n",
        "    all_player_urls = [req.url]\n",
        "    print(soup.title)\n",
        "    search_tag_container = soup.find_all('h5',class_='player-card-description gray-900')\n",
        "    count = 0\n",
        "    for job_elem in search_tag_container:\n",
        "        result.append(job_elem.text)\n",
        "        count+=1\n",
        "    search_tag_container = soup.find_all('p',class_=\"text-uppercase gray-700 mb-0 pb-0-5 player-card-heading\")\n",
        "    player_gender = \"Male\"\n",
        "    for job_elem in search_tag_container:\n",
        "        lab.append(job_elem.text)\n",
        "    player_role = \"xyz\"\n",
        "    for i in range(len(lab)):\n",
        "        if \"role\" in lab[i].lower():\n",
        "            player_role = result[i].lower()\n",
        "            break\n",
        "    ##################################\n",
        "    valid, bat_bowl_soup = evaluate(soup)\n",
        "    if valid != 1:\n",
        "        return\n",
        "    search_tag_container = bat_bowl_soup.findAll('thead')\n",
        "    match_averages = []\n",
        "    runs_scored_as_batsman = 0\n",
        "    balls_bowled_as_bowler = 0\n",
        "    for m in range(len(search_tag_container)):\n",
        "        actual_heading = search_tag_container[m].findPrevious('h5').text\n",
        "        current_string = \"_\"\n",
        "        if \"Bowling\" in actual_heading:\n",
        "            current_string = \"Bowling_\"\n",
        "        elif \"Batting\" in actual_heading:\n",
        "            current_string = \"Batting_\"\n",
        "        else:\n",
        "            continue\n",
        "        match_records = {}\n",
        "        tag_content = search_tag_container[m].find_all('th')\n",
        "        head = 0\n",
        "        table_labels = list()\n",
        "        table_labels_1 =list()\n",
        "        for job_elem in tag_content:\n",
        "            table_labels.append(job_elem.text)\n",
        "            head += 1\n",
        "        # print('Head count',head)\n",
        "\n",
        "        tag_content = search_tag_container[m].findNext('tbody').find_all('td')\n",
        "        track_head_label = 0\n",
        "        current_format = \"\"\n",
        "        for job_elem in tag_content:\n",
        "            attribute_number = track_head_label % head\n",
        "            if(attribute_number != 0):\n",
        "                result.append(job_elem.text)\n",
        "                label_text = table_labels[attribute_number]\n",
        "                lab.append(current_string + current_format + '_' + label_text)\n",
        "                count += 1\n",
        "                if label_text.lower() == \"mat\":\n",
        "                    match_records[current_format.lower()] = job_elem.text\n",
        "                if current_string == \"Batting_\" and label_text.lower() == \"runs\":\n",
        "                    try:\n",
        "                        runs_scored_as_batsman += (int(job_elem.text))\n",
        "                    except:\n",
        "                        pass\n",
        "                elif current_string == \"Bowling_\" and label_text.lower() == \"balls\":\n",
        "                    try:\n",
        "                        balls_bowled_as_bowler += (int(job_elem.text))\n",
        "                    except:\n",
        "                        pass\n",
        "            else:\n",
        "                current_format = job_elem.text\n",
        "                if current_format[0] == 'W':\n",
        "                    player_gender = \"Female\"\n",
        "                    if current_format == \"WTEST\":\n",
        "                        current_format = \"Test\"\n",
        "                    else:\n",
        "                        current_format = current_format[1:]\n",
        "            track_head_label += 1\n",
        "        match_averages.append(match_records)\n",
        "    lab.append(\"Gender\")\n",
        "    result.append(player_gender)\n",
        "    if(len(match_averages) != 2):\n",
        "        return\n",
        "    internationals = 0\n",
        "    non_internationals = 0\n",
        "    for key in match_averages[0]:\n",
        "        if key in match_averages[1]:\n",
        "            if key == \"test\" or key == \"odi\" or key == \"t20i\":\n",
        "                try:\n",
        "                    internationals += max(int(match_averages[0][key]), int(match_averages[1][key]))\n",
        "                except:\n",
        "                    pass\n",
        "            else:\n",
        "                try:\n",
        "                    non_internationals += max(int(match_averages[0][key]), int(match_averages[1][key]))\n",
        "                except:\n",
        "                    pass\n",
        "    if internationals == 0 and non_internationals < 15:\n",
        "        return\n",
        "    if runs_scored_as_batsman < 50 and balls_bowled_as_bowler < 50:\n",
        "        return\n",
        "    if (\"bat\" in player_role or \"keep\" in player_role) and runs_scored_as_batsman < 100:\n",
        "        return\n",
        "    if \"bowl\" in player_role and balls_bowled_as_bowler < 100:\n",
        "        return\n",
        "    if \"round\" in player_role and (runs_scored_as_batsman < 50 or balls_bowled_as_bowler < 50):\n",
        "        return\n",
        "    ####################################\n",
        "    individual_player_id = str(req.url).split('-')[-1]\n",
        "    lab.append(\"Cricinfo_id\")\n",
        "    result.append(individual_player_id)\n",
        "    ####################################\n",
        "    Relations = soup.find('p',class_=\"text-uppercase gray-700 mb-0 player-card-heading text-uppercase\")\n",
        "    #relation_players = soup.find('p',class_=\"player-card-description player-description-link gray-900 m-0 player-link\")\n",
        "    if(Relations != None):\n",
        "        if(Relations.text.lower()=='relations' or Relations.text.lower()=='relation'):\n",
        "            lab.append(\"Relations\")\n",
        "            all_relations = find_relations(Relations)\n",
        "            result.append([all_relations])\n",
        "    ######################################\n",
        "    rec = extra(u)\n",
        "    lab.append(\"Records\")\n",
        "    result.append([rec])\n",
        "    if len(rec) > 0:\n",
        "        all_player_urls.append(u)\n",
        "    # print(result)\n",
        "    ##########################################\n",
        "    records_format , records_data = format_records(u)\n",
        "    for iter in range(len(records_format)):\n",
        "      lab.append(records_format[iter])\n",
        "      result.append([records_data[iter]])\n",
        "    ###########################################\n",
        "    matches = debut(debut_url)\n",
        "    if len(matches) > 0:\n",
        "        all_player_urls.append(debut_url)\n",
        "    current_match_format = \"\"\n",
        "    for match_detail in matches:\n",
        "        match_detail = str(match_detail)\n",
        "        if match_detail.startswith(\"Last\"):\n",
        "            lab.append(current_match_format + \"_\" + \"last_appearance\")\n",
        "            result.append(match_detail[5:])\n",
        "        elif match_detail.startswith(\"Debut\"):\n",
        "            lab.append(current_match_format + \"_\" + \"debut\")\n",
        "            result.append(match_detail[6:])\n",
        "        else:\n",
        "            current_match_format = match_detail\n",
        "            if current_match_format[0] == 'W':\n",
        "                if current_match_format == \"WTEST Matches\":\n",
        "                    current_match_format = \"Test Matches\"\n",
        "                else:\n",
        "                    current_match_format = current_match_format[1:]\n",
        "    ##########################################\n",
        "    lab.append(\"Teams\")\n",
        "    team_data = teams_data(soup)\n",
        "    result.append([team_data])\n",
        "    ###########################################\n",
        "    info_labels, info_results = get_statistical_analysis_and_trophy_info_and_image(req)\n",
        "    lab = lab + info_labels\n",
        "    result = result + info_results\n",
        "    if len(info_results) > 0:\n",
        "        all_player_urls.append(req.url + \"/bowling-batting-stats\")\n",
        "    ###########################################\n",
        "    lab.append(\"References\")\n",
        "    result.append([all_player_urls])\n",
        "    ####################################\n",
        "    career_span_tag = soup.find('div', class_=\"intl_career-desktop\")\n",
        "    try:\n",
        "      career_span_tag_text = career_span_tag.findNext('p').text\n",
        "    except:\n",
        "      career_span_tag_text = \"\"\n",
        "    if len(career_span_tag_text) > 0:\n",
        "        career_span_info = \"\"\n",
        "        start_index = 0\n",
        "        for i in range(len(career_span_tag_text)):\n",
        "            if career_span_tag_text[i] == '1' or career_span_tag_text[i] == '2':\n",
        "                start_index = i\n",
        "                break\n",
        "        career_span_tag_text = career_span_tag_text[start_index:]\n",
        "        result.append(career_span_tag_text)\n",
        "        lab.append(\"career_span\")\n",
        "    ###########################################\n",
        "    search_tag_container = soup.find('div',class_=\"player-card__details\")\n",
        "    player_name = search_tag_container.find(\"h2\").text\n",
        "    country = search_tag_container.find(\"span\",class_=\"player-card__country-name\").text\n",
        "    #player_type = search_tag_container.find(\"div\",class_=\"player-card__player-type\")\n",
        "    l_label = [\"Player_Name\",\"Nationality\"]\n",
        "    l = [player_name,country]\n",
        "    result = result + l\n",
        "    lab = lab + l_label\n",
        "    ##########################\n",
        "      \n",
        "    print('label--',len(lab))\n",
        "    print('result--',len(result))\n",
        "    print(lab)\n",
        "    print(result)\n",
        "    lo = dict(zip(lab,result))\n",
        "    # print(lo)\n",
        "    lp = pd.DataFrame(lo,index=None)\n",
        "    # print(lp)\n",
        "    final_list_players.append(lp)\n",
        "    print('count',count)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNzOA_ZttuAV"
      },
      "source": [
        "#Get individual player's \"Records\" information.\n",
        "import re\n",
        "def extra(l):\n",
        "    re = requests.get(l)\n",
        "    time.sleep(2)\n",
        "    so = bf(re.text,\"html.parser\")\n",
        "    res1 = so.find_all('div',class_='col-14 d-flex flex-row')\n",
        "    res = so.find_all('div',class_='row bg-gray-100 class-record-row-p d-flex align-items-center')\n",
        "    #print(res1)\n",
        "    url_list = list()\n",
        "    for i in range(len(res1)):\n",
        "\n",
        "        pre = res1[i].find_all('h1')\n",
        "        loi = res1[i].find_all('p',class_='record-class-title m-0')\n",
        "        #print(loi)    \n",
        "        for j in range(len(pre)):\n",
        "            #print(pre[j].text)\n",
        "            #print(loi[j].text)\n",
        "            url_list.append(str(pre[j].text)  +str(\" \") + str(loi[j].text))\n",
        "    return url_list\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjnpshJ-VSLr"
      },
      "source": [
        "\n",
        "def format_records(url):\n",
        "  req = requests.get(url)\n",
        "  soup = bf(req.text,\"html.parser\")\n",
        "  record_sections = soup.find_all('div',class_=\"card content-block\")\n",
        "  required = ['Test Records','ODI Records','T20I Records']\n",
        "  available_labels = list()\n",
        "  labels_data = list()\n",
        "  count = -1\n",
        "  for i in range(len(record_sections)):\n",
        "    name = record_sections[i].find('h5',class_=\"m-0\")\n",
        "    if(name.text in required):\n",
        "      available_labels.append(name.text)\n",
        "      labels_data.append([])\n",
        "      count +=1\n",
        "      individual_block_record = record_sections[i].find_all('a',class_=\"gray-900 benton-normal d-block\")\n",
        "      for i in range(len(individual_block_record)):\n",
        "        try:\n",
        "          a = individual_block_record[i].find('span',class_=\"m-0 benton-bold gray-1000 pr-3\").text\n",
        "          b = individual_block_record[i].find('span',class_=\"list-record-title\").text\n",
        "          c = individual_block_record[i].find('span',class_=\"m-0 ml-1 gray-600\").text\n",
        "          labels_data[count].append(str(a)+str(\" \")+str(b)+str(\" \")+str(c))\n",
        "        except:\n",
        "          no = 1\n",
        "  return available_labels , labels_data"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFMqUqH6ON_2"
      },
      "source": [
        "def teams_data(so):\n",
        "  teams = []\n",
        "  loi = so.find_all('h5',class_='m-0 ml-2 link-border-bottom player-description-link')\n",
        "  for i in range(len(loi)):\n",
        "    teams.append(loi[i].text)\n",
        "  return teams"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ho2v5lYXUjZ"
      },
      "source": [
        "def debut(link):\n",
        "  player_match = list()\n",
        "  url = link\n",
        "  request = requests.get(url)\n",
        "  soup = bf(request.text,\"html.parser\")\n",
        "  search_tag_container = soup.find_all('div',{'id':'debut-last-matches'})\n",
        "  cp_jo = search_tag_container\n",
        "  if(len(search_tag_container) != 0):\n",
        "    total = cp_jo[0].find_all('div',class_=\"\")\n",
        "    for i in range(len(total)):\n",
        "      p =total[i]\n",
        "      a= p.find('h5',{'class':\"benton-bold player-matches-subtitle d-flex justify-content-between align-items-center player_matches-dropdown m-0\"})\n",
        "      k = total[i].find_all('span',class_=\"match-event-row-debut-last white-space-nowrap\")\n",
        "      search_tag_container = total[i].find_all('span',{\"class\": \"player-match-link\"})\n",
        "      new = total[i].find_all('div',{\"class\":\"col-12 player-match-event-cell white-space-nowrap\"})\n",
        "      #print(a)\n",
        "      #print(k[0])\n",
        "      #print(new)\n",
        "      try:\n",
        "        l =a.span.decompose()\n",
        "      except:\n",
        "        player_match.append(a.text)\n",
        "        #print(a.text)\n",
        "      else:\n",
        "        player_match.append(a.text)\n",
        "        #print(a.text)\n",
        "      for j in range(len(k)):\n",
        "        try:\n",
        "          temp = search_tag_container[j].text\n",
        "        except:\n",
        "          temp = new[j].text\n",
        "        append = k[j].text + str(\" \") + temp\n",
        "        player_match.append(append)\n",
        "        #print(k[j].text,end=\" \")\n",
        "        #print(search_tag_container[j].text)\n",
        "  return player_match"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9c0G1FctuAW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "outputId": "c319cb75-b2a9-4258-9df2-4a6968e99cee"
      },
      "source": [
        "import time\n",
        "final_list_players = list()\n",
        "for country_id in range(1,2):\n",
        "  #Country based parse url\n",
        "  for letter in range(65,91):\n",
        "    url = \"https://www.espncricinfo.com/ci/content/player/country.html?country=\"+str(country_id)+\";alpha=\"+str(chr(letter))\n",
        "    req = requests.get(url)\n",
        "    print(url)\n",
        "    soup = bf(req.text,\"html.parser\")\n",
        "    #Fetch total urls of players belonging to a country\n",
        "    #country_name = soup.find('span',{'id':'ciShowCountry'})\n",
        "    country_name = soup.find('div',{\"class\":\"icc-home\"})\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(country_name.text)\n",
        "    print(\"-------------------------------------------------\")\n",
        "    search_tag_container = soup.find_all('td')\n",
        "    u = list()\n",
        "    for job_elem in search_tag_container:\n",
        "        u.append(job_elem.find('a'))\n",
        "        #result.append(job_elem.text)\n",
        "    l = set(u)\n",
        "    l = list(l)\n",
        "    for i in range(len(l)):\n",
        "        u = \"https://www.espncricinfo.com\"\n",
        "        if l[i] is None:\n",
        "            continue\n",
        "        if not l[i].has_attr(\"href\"):\n",
        "            continue\n",
        "        rl = l[i][\"href\"]\n",
        "        link = u+rl\n",
        "        print(link)\n",
        "        #link = \"https://www.espncricinfo.com/player/virat-kohli-253802\"\n",
        "        req = requests.get(link)\n",
        "        time.sleep(2)\n",
        "        print('player-',i,end=\" \")\n",
        "        ind = len(final_list_players)\n",
        "        record_url = req.url+str(\"/tests-odi-t20-records\")\n",
        "        debut_url = req.url+str(\"/matches\")\n",
        "        #debut(debut_url)\n",
        "        load(req,final_list_players,ind,record_url,debut_url)\n",
        "        #print(record_url)\n",
        "        #jk = extra(record_url)\n",
        "        #print(jk)\n",
        "    try:\n",
        "      driver.close()\n",
        "    except:\n",
        "      no_drive = 1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://www.espncricinfo.com/ci/content/player/country.html?country=6\n",
            "-------------------------------------------------\n",
            "\n",
            "\n",
            "Players / India\n",
            "\t\t\t\t\n",
            "\n",
            "-------------------------------------------------\n",
            "https://www.espncricinfo.com/ci/content/player/430246.html\n",
            "player- 0 <title>Yuzvendra Chahal profile and biography, stats, records, averages, photos and videos</title>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MaxRetryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 159\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1276\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1271\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    971\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 168\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7f6ec91d18d0>: Failed to establish a new connection: [Errno 111] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5f0e8ae0a261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mdebut_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/matches\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#debut(debut_url)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_list_players\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecord_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebut_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;31m#print(record_url)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#jk = extra(record_url)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-a7d17c5ac518>\u001b[0m in \u001b[0;36mload\u001b[0;34m(req, final_list_players, ind, u, debut_url)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mteam_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m###########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0minfo_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_statistical_analysis_and_trophy_info_and_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0mlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlab\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minfo_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minfo_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-4d629ef39abb>\u001b[0m in \u001b[0;36mget_statistical_analysis_and_trophy_info_and_image\u001b[0;34m(req)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# selecting dropdown option\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# loading page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     70\u001b[0m             return self.request_encode_body(method, url, fields=fields,\n\u001b[1;32m     71\u001b[0m                                             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                                             **urlopen_kw)\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     def request_encode_url(self, method, url, fields=None, headers=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m                                 **response_kw)\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdrain_and_release_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m                                 **response_kw)\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdrain_and_release_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m                                 **response_kw)\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdrain_and_release_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Incremented Retry for (url='%s'): %r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=54489): Max retries exceeded with url: /session/4699e2c096150a70d4f4ec77ef2fb10f/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6ec91d18d0>: Failed to establish a new connection: [Errno 111] Connection refused'))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPEr342-A2V2"
      },
      "source": [
        "a = final_list_players[0]\n",
        "df = a.T\n",
        "for i in range(1,len(final_list_players)):\n",
        "    lo = final_list_players[i].T\n",
        "    df = pd.concat([df,lo],axis=1)\n",
        "final_df = df.T\n",
        "final_df.to_csv(\"output_players.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTpdYlfTGnfl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}